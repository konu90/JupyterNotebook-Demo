{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time as tm\n",
    "\n",
    "#Method to load excel with pandas\n",
    "#loadDF = pd.read_excel(\"../CopiaDatosMATLAB.xlsx\")\n",
    "#Method to load excel with pandas\n",
    "loadDF = pd.read_csv(\"../data sampled every 10th sec.csv\", delimiter=';')\n",
    "#Drop useless rows of header\n",
    "loadDF = loadDF.drop(loadDF.index[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#rename Columns\n",
    "df = loadDF.rename(\n",
    "    {\n",
    "        'Cañuelas/Ezeiza #3 (S01)': 'Timestamp',\n",
    "        'CFA10CE001/XE01':'Active Load',\n",
    "        'MBA10AE005/XG01':'Variable Guide Vane',\n",
    "        'MBA10CP010/XE01':'Compressor Inlet Pressure',\n",
    "        'MBA10CP015/XE01':'Press Comp Outlet.1',\n",
    "        'MBA10CP016/XE01':'Press Comp Outlet.2',\n",
    "        'MBA10CP017/XE01':'Press Comp Outlet.3',\n",
    "        'MBA10CP040/XE01':'Turbine Exhaust Diff Pressure.1',\n",
    "        'MBA10CP041/XE01':'Turbine Exhaust Diff Pressure.2',\n",
    "        'MBA10CP042/XE01':'Turbine Exhaust Diff Pressure.3',\n",
    "        'MBA10CP045/XE01':'Turbine Exhaust Pressure',\n",
    "        'MBA10CP065/XE01':'Air Intake Diff Pressure.1',\n",
    "        'MBA10CP075/XE01':'Air Intake Diff Pressure.2',\n",
    "        'MBA10CS005/XE01':'NT1 Rotor Speed',\n",
    "        'MBA10CS010/XE01':'NT2 Rotor Speed',\n",
    "        'MBA10CT025/XE01':'Compressor Inlet Temperature.1',\n",
    "        'MBA10CT026/XE01':'Compressor Inlet Temperature.2',\n",
    "        'MBA10CT027/XE01':'Compressor Inlet Temperature.3',\n",
    "        'MBA10CT030/XE01':'Compressor Outlet Temperature.1',\n",
    "        'MBA10CT031/XE01':'Compressor Outlet Temperature.2',\n",
    "        'MBA10CT032/XE01':'Compressor Outlet Temperature.3',\n",
    "        'MBA10CT100/XE01':'Exhaust Temperature 1.1',\n",
    "        'MBA10CT100/XE02':'Exhaust Temperature 1.2',\n",
    "        'MBA10CT100/XE03':'Exhaust Temperature 1.3',\n",
    "        'MBA10CT105/XE01':'Exhaust Temperature 2.1',\n",
    "        'MBA10CT105/XE02':'Exhaust Temperature 2.2',\n",
    "        'MBA10CT105/XE03':'Exhaust Temperature 2.3',\n",
    "        'MBA10CT110/XE01':'Exhaust Temperature 3.1',\n",
    "        'MBA10CT110/XE02':'Exhaust Temperature 3.2',\n",
    "        'MBA10CT110/XE03':'Exhaust Temperature 3.3',\n",
    "        'MBA10CT115/XE01':'Exhaust Temperature 4.1',\n",
    "        'MBA10CT115/XE02':'Exhaust Temperature 4.2',\n",
    "        'MBA10CT115/XE03':'Exhaust Temperature 4.3',\n",
    "        'MBA10CT120/XE01':'Exhaust Temperature 5.1',\n",
    "        'MBA10CT120/XE02':'Exhaust Temperature 5.2',\n",
    "        'MBA10CT120/XE03':'Exhaust Temperature 5.3',\n",
    "        'MBA10CT125/XE01':'Exhaust Temperature 6.1',\n",
    "        'MBA10CT125/XE02':'Exhaust Temperature 6.2',\n",
    "        'MBA10CT125/XE03':'Exhaust Temperature 6.3',\n",
    "        'MBA10CT130/XE01':'Exhaust Temperature 7.1',\n",
    "        'MBA10CT130/XE02':'Exhaust Temperature 7.2',\n",
    "        'MBA10CT130/XE03':'Exhaust Temperature 7.3',\n",
    "        'MBA10CT135/XE01':'Exhaust Temperature 8.1',\n",
    "        'MBA10CT135/XE02':'Exhaust Temperature 8.2',\n",
    "        'MBA10CT135/XE03':'Exhaust Temperature 8.3',\n",
    "        'MBA10CT140/XE01':'Exhaust Temperature 9.1',\n",
    "        'MBA10CT140/XE02':'Exhaust Temperature 9.2',\n",
    "        'MBA10CT140/XE03':'Exhaust Temperature 9.3',\n",
    "        'MBA10CT145/XE01':'Exhaust Temperature 10.1',\n",
    "        'MBA10CT145/XE02':'Exhaust Temperature 10.2',\n",
    "        'MBA10CT145/XE03':'Exhaust Temperature 10.3',\n",
    "        'MBA10CT150/XE01':'Exhaust Temperature 11.1',\n",
    "        'MBA10CT150/XE02':'Exhaust Temperature 11.2',\n",
    "        'MBA10CT150/XE03':'Exhaust Temperature 11.3',\n",
    "        'MBA10CT155/XE01':'Exhaust Temperature 12.1',\n",
    "        'MBA10CT155/XE02':'Exhaust Temperature 12.2',\n",
    "        'MBA10CT155/XE03':'Exhaust Temperature 12.3',\n",
    "        'MBA10CT160/XE01':'Exhaust Temperature 13.1',\n",
    "        'MBA10CT160/XE02':'Exhaust Temperature 13.2',\n",
    "        'MBA10CT160/XE03':'Exhaust Temperature 13.3',\n",
    "        'MBA10CT165/XE01':'Exhaust Temperature 14.1',\n",
    "        'MBA10CT165/XE02':'Exhaust Temperature 14.2',\n",
    "        'MBA10CT165/XE03':'Exhaust Temperature 14.3',\n",
    "        'MBA10CT170/XE01':'Exhaust Temperature 15.1',\n",
    "        'MBA10CT170/XE02':'Exhaust Temperature 15.2',\n",
    "        'MBA10CT170/XE03':'Exhaust Temperature 15.3',\n",
    "        'MBA10CT175/XE01':'Exhaust Temperature 16.1',\n",
    "        'MBA10CT175/XE02':'Exhaust Temperature 16.2',\n",
    "        'MBA10CT175/XE03':'Exhaust Temperature 16.3',\n",
    "        'MBA10FF900/XE01':'Turbine Inlet Massflow',\n",
    "        'MBA10FT903/XE01':'Turbine Inlet Temperature (T52)',\n",
    "        'MBA10FT910/ZE01':'T7 Exhaust Temp Average',\n",
    "        'MBL30CM005/XE01':'Ambient Air Humidity',\n",
    "        'MBL30CT005/XE01':'Ambient Air Temperature',\n",
    "        'MBP10CT005/XE01':'Gas Fuel Temperature.1',\n",
    "        'MBP10CT006/XE01':'Gas Fuel Temperature.2',\n",
    "        'MBP10CT007/XE01':'Gas Fuel Temperature.3',\n",
    "        'MKA10CE014/XE01':'Generator Power Factor',\n",
    "        'MKY10CS010/XE01':'Generator Frequency'\n",
    "    },  axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete columns useless\n",
    "df = df.drop(\n",
    "    ['BAC10GS101/XP01',\n",
    "    'BAC10GS101/XP11',\n",
    "    'Generator Power Factor', \n",
    "    'Generator Frequency',\n",
    "    'Turbine Inlet Massflow',\n",
    "    'NT1 Rotor Speed',\n",
    "    'NT2 Rotor Speed']\n",
    "     , axis=1)\n",
    "#Drop Timestamp from individual sensors\n",
    "for i in range (1,80):\n",
    "    column = 'Cañuelas/Ezeiza #3 (S01).' + str(i)\n",
    "    df = df.drop([column], axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change types\n",
    "#Replace \",\" to \".\"\n",
    "df = df.applymap(lambda x: x.replace(',', '.'))\n",
    "#Convert values to numeric values\n",
    "df[df.columns[1:74]] = df[df.columns[1:74]].apply(pd.to_numeric, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Get AVG values to each group of characteristics\n",
    "df['Press Comp Outlet'] = df[['Press Comp Outlet.1', 'Press Comp Outlet.2','Press Comp Outlet.3']].mean(axis=1)\n",
    "df = df.drop(['Press Comp Outlet.1','Press Comp Outlet.2','Press Comp Outlet.3'],axis=1)\n",
    "df['Turbine Exhaust Diff Pressure'] = df[['Turbine Exhaust Diff Pressure.1', 'Turbine Exhaust Diff Pressure.2','Turbine Exhaust Diff Pressure.3']].mean(axis=1)\n",
    "df = df.drop(['Turbine Exhaust Diff Pressure.1','Turbine Exhaust Diff Pressure.2','Turbine Exhaust Diff Pressure.3'],axis=1)\n",
    "df['Air Intake Diff Pressure'] = df[['Air Intake Diff Pressure.1', 'Air Intake Diff Pressure.2']].mean(axis=1)\n",
    "df = df.drop(['Air Intake Diff Pressure.1', 'Air Intake Diff Pressure.2'],axis=1)\n",
    "df['Compressor Inlet Temperature'] = df[['Compressor Inlet Temperature.1', 'Compressor Inlet Temperature.2', 'Compressor Inlet Temperature.3']].mean(axis=1)\n",
    "df = df.drop(['Compressor Inlet Temperature.1', 'Compressor Inlet Temperature.2', 'Compressor Inlet Temperature.3'],axis=1)\n",
    "df['Compressor Outlet Temperature'] = df[['Compressor Outlet Temperature.1', 'Compressor Outlet Temperature.2', 'Compressor Outlet Temperature.3']].mean(axis=1)\n",
    "df = df.drop(['Compressor Outlet Temperature.1', 'Compressor Outlet Temperature.2', 'Compressor Outlet Temperature.3'],axis=1)\n",
    "for i in range(1,17):\n",
    "    name = 'Exhaust Tempeture ' + str(i)\n",
    "    subname1 = 'Exhaust Temperature ' + str(i) + '.1'\n",
    "    subname2 = 'Exhaust Temperature ' + str(i) + '.2'\n",
    "    subname3 = 'Exhaust Temperature ' + str(i) + '.3'\n",
    "    df[name] = df[[subname1, subname2, subname3]].mean(axis=1)\n",
    "    df = df.drop([subname1, subname2, subname3], axis=1)\n",
    "df['Gas Fuel Temperature'] = df[['Gas Fuel Temperature.1', 'Gas Fuel Temperature.2', 'Gas Fuel Temperature.3']].mean(axis=1)\n",
    "df = df.drop(['Gas Fuel Temperature.1', 'Gas Fuel Temperature.2', 'Gas Fuel Temperature.3'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dataframe\n",
    "df.to_csv(\"../preprocessData.csv\", sep =';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Delete Timestamp to evade problems with PCA\n",
    "df_dibujar = df.copy()\n",
    "del df_dibujar['Timestamp']\n",
    "#Normalize\n",
    "df_normalized = preprocessing.normalize(df_dibujar, norm='l2')\n",
    "\n",
    "x = df_dibujar.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df_dibujar = pd.DataFrame(x_scaled)\n",
    "\n",
    "# #PCA\n",
    "# Select number of components\n",
    "pca = decomposition.PCA(n_components=3)\n",
    "#Apply PCA on dataframe and the variable that have the number of component of PCA\n",
    "principalComponents = pca.fit_transform(df_dibujar)\n",
    "#Save the result in a dataframe(principalDF)\n",
    "principalDF = pd.DataFrame(data = principalComponents, columns = ['PC1', 'PC2', 'PC3'])\n",
    "\n",
    "#Para ver el grado de variabilidad de las componentes elegidas\n",
    "pca.explained_variance_ratio_\n",
    "\n",
    "#Visualizar los datos\n",
    "#plt.scatter(componente X, componente Y, ...)\n",
    "plt.scatter(principalDF[['PC1']], principalDF[['PC2']], principalDF[['PC3']])\n",
    "#Etiquetas para los ejes\n",
    "plt.xlabel('principal component 1')\n",
    "plt.ylabel('principal component 2')\n",
    "#Mostrar titulo de grafica\n",
    "plt.title('About as simple as it gets, folks')\n",
    "#Dibujar rejilla\n",
    "plt.grid(True)\n",
    "#Guardar grafica en imagen\n",
    "#plt.savefig(\"test.png\")\n",
    "#mostrar grafica en notebook\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Painting PCA graphs in 3 dimensions\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection = '3d')\n",
    "\n",
    "ax.scatter(principalDF[['PC1']], principalDF[['PC2']], principalDF[['PC3']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Kmeans on dataframe\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, n_init=50, max_iter=500)\n",
    "kmeans.fit(principalDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save centers of cluster of kmeans\n",
    "centroids = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save labels of each row grouped by kmeans algorithm\n",
    "labels = kmeans.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose colors\n",
    "colors = [\"g.\",\"r.\",\"b.\",\"y.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot all point with colors of clusters\n",
    "for i in range(len(principalDF)):\n",
    "    #print(\"coordinate:\",principalDF['PC1'], \"label:\", labels[i])\n",
    "    plt.plot(principalDF['PC1'][i],principalDF['PC2'][i],principalDF['PC3'][i], colors[labels[i]])\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot in a 3D graphs group of kmeans about PCA\n",
    "fig2 = plt.figure()\n",
    "ax2 = fig2.add_subplot(111, projection = '3d')\n",
    "ax2.scatter(principalDF['PC1'], principalDF['PC2'], principalDF['PC3'], c = labels)\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save in dataframe the labels of kmeans\n",
    "df.loc[:, 'Cluster'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot timestams vs ActiveLoad with a label of kmeans\n",
    "plt.scatter(df['Timestamp'], df['Active Load'], c = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load csv labeled by expert judgment\n",
    "labeled = pd.read_csv(\"../labeled.csv\", delimiter=';')\n",
    "#del labeled['Timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot with scatter function(axis x, axis y, c = color by column)\n",
    "plt.scatter(labeled['Timestamp'], labeled['Active Load'], c = labeled['Cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to split a dataframe according to a %\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(labeled, test_size=0.2)\n",
    "train = train.sort_index(ascending=[1])\n",
    "test = test.sort_index(ascending=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load train dataframe\n",
    "traindf = pd.read_csv(\"../train.csv\", delimiter=';')\n",
    "del traindf['Timestamp']\n",
    "#Load test dataframe\n",
    "testdf = pd.read_csv(\"../test.csv\", delimiter=';')\n",
    "#Conver tipe from column \"Cluster\"\n",
    "testdf['Cluster'] = testdf['Cluster'].astype(np.int)\n",
    "del testdf['Timestamp']\n",
    "#Prepare test dataframe only with data of his cluster\n",
    "testCluster0 = testdf.loc[testdf['Cluster'] == 0]\n",
    "testCluster1 = testdf.loc[testdf['Cluster'] == 1]\n",
    "testCluster2 = testdf.loc[testdf['Cluster'] == 2]\n",
    "testCluster3 = testdf.loc[testdf['Cluster'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we know the clusters, we will train a classification algorithm (SVM)\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = svm.SVC(gamma=0.0001, C=100)\n",
    "clf.fit(traindf,traindf['Cluster'])\n",
    "#Apply Accuracy_score to prediction of SVM\n",
    "#prepare values\n",
    "prediction = clf.predict(testdf)\n",
    "truevalue = testdf['Cluster']\n",
    "#Apply Accuracy_score(true label, predicted label)\n",
    "print(\"Accuracy All cluster\")\n",
    "print(accuracy_score(truevalue, prediction))\n",
    "#Este es el mejor resultado aprox, en el que clasifica correctamente los cluster 0(apagada) y cluster 2(max potencia)\n",
    "#Se confunde en los cluster 1(encendiendose) y 3(apagandose) lo que es normal porque atomicamente son los mismos datos\n",
    "#Tal vez se podria añadir un parametro que indique si la carga activa a aumentado con respecto al parametro anterior\n",
    "#de manera que se diferencien ambas clases\n",
    "#print the number of cluster predicted with SVM\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################Test Cluster 0\n",
    "clf = svm.SVC(gamma=0.0001, C=100)\n",
    "clf.fit(traindf,traindf['Cluster'])\n",
    "#Apply Accuracy_score to prediction of SVM\n",
    "#prepare values\n",
    "prediction = clf.predict(testCluster0)\n",
    "truevalue = testCluster0['Cluster']\n",
    "#Apply Accuracy_score(true label, predicted label)\n",
    "print(\"Accuracy Cluster 0\")\n",
    "print(accuracy_score(truevalue, prediction))\n",
    "#######################Test Cluster 1\n",
    "clf = svm.SVC(gamma=0.0001, C=100)\n",
    "clf.fit(traindf,traindf['Cluster'])\n",
    "#Apply Accuracy_score to prediction of SVM\n",
    "#prepare values\n",
    "prediction = clf.predict(testCluster1)\n",
    "truevalue = testCluster1['Cluster']\n",
    "#Apply Accuracy_score(true label, predicted label)\n",
    "print(\"Accuracy Cluster 1\")\n",
    "print(accuracy_score(truevalue, prediction))\n",
    "####################TEST CLUSTER 2\n",
    "clf = svm.SVC(gamma=0.0001, C=100)\n",
    "clf.fit(traindf,traindf['Cluster'])\n",
    "#Apply Accuracy_score to prediction of SVM\n",
    "#prepare values\n",
    "prediction = clf.predict(testCluster2)\n",
    "truevalue = testCluster2['Cluster']\n",
    "#Apply Accuracy_score(true label, predicted label)\n",
    "print(\"Accuracy Cluster 2\")\n",
    "print(accuracy_score(truevalue, prediction))\n",
    "####################Test Cluster 3\n",
    "clf = svm.SVC(gamma=0.0001, C=100)\n",
    "clf.fit(traindf,traindf['Cluster'])\n",
    "#Apply Accuracy_score to prediction of SVM\n",
    "#prepare values\n",
    "prediction = clf.predict(testCluster3)\n",
    "truevalue = testCluster3['Cluster']\n",
    "#Apply Accuracy_score(true label, predicted label)\n",
    "print(\"Accuracy Cluster 3\")\n",
    "print(accuracy_score(truevalue, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to obtain a 20% of threshold according to a value. Return the new value with threshold\n",
    "def getMinThreshold( x):\n",
    "    if( x > 0):\n",
    "        return x * 0.8\n",
    "    else:\n",
    "        return x * 1.2\n",
    "def getMaxThreshold(x):\n",
    "    if( x > 0):\n",
    "        return x * 1.2\n",
    "    else:\n",
    "        return x * 0.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get avg values from all data to each column in order to get level of normal run\n",
    "#Prepare dataframes according to his cluster\n",
    "labeledWTS = pd.read_csv(\"../labeledWTS.csv\", delimiter=';')\n",
    "\n",
    "dfCluster0 = labeledWTS.loc[labeled['Cluster'] == 0]\n",
    "dfCluster1 = labeledWTS.loc[labeled['Cluster'] == 1]\n",
    "dfCluster2 = labeledWTS.loc[labeled['Cluster'] == 2]\n",
    "dfCluster3 = labeledWTS.loc[labeled['Cluster'] == 3]\n",
    "#Get a row with avg values of all column for each cluster\n",
    "avgCluster0 = dfCluster0.mean(axis=0)\n",
    "avgCluster1 = dfCluster1.mean(axis=0)\n",
    "avgCluster2 = dfCluster2.mean(axis=0)\n",
    "avgCLuster3 = dfCluster3.mean(axis=0)\n",
    "#Get a row with max values of all column for each cluster\n",
    "maxCluster0 = dfCluster0.max(axis=0)\n",
    "maxCluster1 = dfCluster1.max(axis=0)\n",
    "maxCluster2 = dfCluster2.max(axis=0)\n",
    "maxCluster3 = dfCluster3.max(axis=0)\n",
    "#Get a row with min values of all column for each cluster\n",
    "minCluster0 = dfCluster0.min(axis=0)\n",
    "minCluster1 = dfCluster1.min(axis=0)\n",
    "minCluster2 = dfCluster2.min(axis=0)\n",
    "minCluster3 = dfCluster3.min(axis=0)\n",
    "#Get a row with max values with a tolerance of 20% for each cluster\n",
    "maxToleranceCluster0 = maxCluster0.apply(lambda x: getMaxThreshold(x))\n",
    "maxToleranceCluster1 = maxCluster1.apply(lambda x: getMaxThreshold(x))\n",
    "maxToleranceCluster2 = maxCluster2.apply(lambda x: getMaxThreshold(x))\n",
    "maxToleranceCluster3 = maxCluster3.apply(lambda x: getMaxThreshold(x))\n",
    "#Get a row with min values with a tolerance of 20%\n",
    "minToleranceCluster0 = minCluster0.apply(lambda x: getMinThreshold(x))\n",
    "minToleranceCluster1 = minCluster1.apply(lambda x: getMinThreshold(x))\n",
    "minToleranceCluster2 = minCluster2.apply(lambda x: getMinThreshold(x))\n",
    "minToleranceCluster3 = minCluster3.apply(lambda x: getMinThreshold(x))\n",
    "#Get quartiles Q1, Q2 and Q3 values of all column for each cluster\n",
    "quantilesCluster0 = dfCluster0.quantile([0.25, 0.5, 0.75])\n",
    "quantilesCluster1 = dfCluster1.quantile([0.25, 0.5, 0.75])\n",
    "quantilesCluster2 = dfCluster2.quantile([0.25, 0.5, 0.75])\n",
    "quantilesCluster3 = dfCluster3.quantile([0.25, 0.5, 0.75])\n",
    "#IQR = Q3 − Q1 RangeInterquantil\n",
    "#Calculate IQR of all column for each cluster\n",
    "iqrCluster0 = quantilesCluster0.loc[0.75] - quantilesCluster0.loc[0.25]\n",
    "iqrCluster1 = quantilesCluster1.loc[0.75] - quantilesCluster1.loc[0.25]\n",
    "iqrCluster2 = quantilesCluster2.loc[0.75] - quantilesCluster2.loc[0.25]\n",
    "iqrCluster3 = quantilesCluster3.loc[0.75] - quantilesCluster3.loc[0.25]\n",
    "#point in the interval [Q1−1.5 ∗ I QR, Q3+1.5 ∗ I QR] is mild outlier\n",
    "#Calculate mild outlier\n",
    "mildOutlierCluster0Bot = (quantilesCluster0.loc[0.25] - iqrCluster0.loc[:] * 1.5)\n",
    "mildOutlierCluster0Top = (quantilesCluster0.loc[0.75] + iqrCluster0.loc[:] * 1.5)\n",
    "mildOutlierCluster1Bot = (quantilesCluster1.loc[0.25] - iqrCluster1.loc[:] * 1.5)\n",
    "mildOutlierCluster1Top = (quantilesCluster1.loc[0.75] + iqrCluster1.loc[:] * 1.5)\n",
    "mildOutlierCluster2Bot = (quantilesCluster2.loc[0.25] - iqrCluster2.loc[:] * 1.5)\n",
    "mildOutlierCluster2Top = (quantilesCluster2.loc[0.75] + iqrCluster2.loc[:] * 1.5)\n",
    "mildOutlierCluster3Bot = (quantilesCluster3.loc[0.25] - iqrCluster3.loc[:] * 1.5)\n",
    "mildOutlierCluster3Top = (quantilesCluster3.loc[0.75] + iqrCluster3.loc[:] * 1.5)\n",
    "#point outside of interval [Q1 − 3 ∗ I QR, Q3 + 3 ∗ I QR] is extreme outlier\n",
    "#Calculate extreme outlier\n",
    "extremeOutlierCluster0Bot = (quantilesCluster0.loc[0.25] - iqrCluster0.loc[:] * 3)\n",
    "extremeOutlierCluster0Top = (quantilesCluster0.loc[0.75] + iqrCluster0.loc[:] * 3)\n",
    "extremeOutlierCluster1Bot = (quantilesCluster1.loc[0.25] - iqrCluster1.loc[:] * 3)\n",
    "extremeOutlierCluster1Top = (quantilesCluster1.loc[0.75] + iqrCluster1.loc[:] * 3)\n",
    "extremeOutlierCluster2Bot = (quantilesCluster2.loc[0.25] - iqrCluster2.loc[:] * 3)\n",
    "extremeOutlierCluster2Top = (quantilesCluster2.loc[0.75] + iqrCluster2.loc[:] * 3)\n",
    "extremeOutlierCluster3Bot = (quantilesCluster3.loc[0.25] - iqrCluster3.loc[:] * 3)\n",
    "extremeOutlierCluster3Top = (quantilesCluster3.loc[0.75] + iqrCluster3.loc[:] * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "dfSimFiveRows = testCluster0.loc[:4]\n",
    "rowToPredict = dfSimFiveRows.mean(axis=0)\n",
    "#Only for testing alterate all values of row\n",
    "rowToPredict2 = rowToPredict.apply(lambda x: x + 5000)\n",
    "#Only for testing, alterate a value of row\n",
    "rowToPredict3 = rowToPredict.copy()\n",
    "rowToPredict3['Active Load'] = rowToPredict3['Active Load'] + 100\n",
    "rowToPredict3['Variable Guide Vane'] = rowToPredict3['Variable Guide Vane'] + 2000\n",
    "rowToPredict3[8] = rowToPredict3[8] + 6900\n",
    "\n",
    "errores = []\n",
    "\n",
    "fiveRowsPredicted = clf.predict([rowToPredict])\n",
    "if(fiveRowsPredicted == 0):\n",
    "    # Apply Range IQR to rowToPredict\n",
    "    allValuesOK = (rowToPredict3[:30] > minToleranceCluster0[:30]) & (rowToPredict3[:30] < maxToleranceCluster0[:30])\n",
    "    for i in range (0 , allValuesOK.shape[0]):\n",
    "        if allValuesOK[i] == False:\n",
    "            errores.append(allValuesOK.axes[0][i])\n",
    "\n",
    "    \n",
    "    if(errores == []):\n",
    "        print (\"Cluster\",fiveRowsPredicted[0], \" - Everything ok\")\n",
    "    else:\n",
    "        print (\"Cluster\",fiveRowsPredicted[0], \" - Failure detection on sensors: \")\n",
    "        print(errores, sep=\", \",)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para borrar, este comando simplifica la visualización\n",
    "# df=df[df.columns[2:5]]\n",
    "numWindows = 0\n",
    "windowDF = pd.DataFrame()\n",
    "# Loop for streaming simulation (it must be changed to a FIFO heap with Python)\n",
    "for i in range (0,testdf.shape[0],5):\n",
    "    #Get a small windows from streaming\n",
    "    smallDF = testdf[i:i+5]\n",
    "    tm.sleep(0.5)\n",
    "    # smallDF forms the windowDF.\n",
    "    # Join windowsDF with smallDF\n",
    "    windowDF = windowDF.append(smallDF)\n",
    "    # When windowDF reaches treshold (5), we compute it\n",
    "    # and clean smallDF\n",
    "    if windowDF.shape[0]== 5:\n",
    "        #print iteration\n",
    "        print(\"Machine Learning Algorithm exec. \", numWindows+1)\n",
    "        #Calculate Summary from streaming\n",
    "        rowToPredict = smallDF.mean(axis=0)\n",
    "        errores = []\n",
    "        #Predict a row with SVM\n",
    "        prediction = clf.predict([rowToPredict])\n",
    "        #Apply a determined threshold to each cluster\n",
    "        #Cluster 0\n",
    "        if(prediction == 0):\n",
    "            #Apply Range IQR\n",
    "            allValuesOK = (rowToPredict[:30] > minToleranceCluster0[:30]) & (rowToPredict[:30] < maxToleranceCluster0[:30])\n",
    "            #Save label from sensors errors\n",
    "            for i in range (0 , allValuesOK.shape[0]):\n",
    "                if allValuesOK[i] == False:\n",
    "                    errores.append(allValuesOK.axes[0][i])\n",
    "        #Cluster 1\n",
    "        elif(prediction == 1):\n",
    "            #Apply Range IQR\n",
    "            allValuesOK = (rowToPredict[:30] > minToleranceCluster1[:30]) & (rowToPredict[:30] < maxToleranceCluster1[:30])\n",
    "            #Save label from sensors errors\n",
    "            for i in range (0 , allValuesOK.shape[0]):\n",
    "                if allValuesOK[i] == False:\n",
    "                    errores.append(allValuesOK.axes[0][i])\n",
    "        #Cluster 2\n",
    "        elif(prediction == 2):\n",
    "            #Apply Range IQR\n",
    "            allValuesOK = (rowToPredict[:30] > minToleranceCluster2[:30]) & (rowToPredict[:30] < maxToleranceCluster2[:30])\n",
    "            #Save label from sensors errors\n",
    "            for i in range (0 , allValuesOK.shape[0]):\n",
    "                if allValuesOK[i] == False:\n",
    "                    errores.append(allValuesOK.axes[0][i])\n",
    "        #Cluster 3\n",
    "        elif(prediction == 3):\n",
    "            #Apply Range IQR\n",
    "            allValuesOK = (rowToPredict[:30] > minToleranceCluster3[:30]) & (rowToPredict[:30] < maxToleranceCluster3[:30])\n",
    "            #Save label from sensors errors\n",
    "            for i in range (0 , allValuesOK.shape[0]):\n",
    "                if allValuesOK[i] == False:\n",
    "                    errores.append(allValuesOK.axes[0][i])\n",
    "        #Print errors founded\n",
    "        if(errores == []):\n",
    "            print (\"Cluster\",prediction[0], \" - Everything ok\")\n",
    "        else:\n",
    "            print (\"Cluster\",prediction[0], \" - Failure detection on sensors: \")\n",
    "            print(errores, sep=\", \",)\n",
    "        \n",
    "        #Reset Windows\n",
    "        smallDF=pd.DataFrame()\n",
    "        windowDF=pd.DataFrame()\n",
    "        numWindows += 1  \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
